ShardingSphere 网站：https://shardingsphere.apache.org/document/legacy/3.x/document/cn/overview/



### 访问数据库超时

例子：一个内容社交公司，在22~23点会访问不了系统，过了这段时间后就可以访问

分析：

1. 这个时间段刚好对应了访问量比较大的情况，而且事后系统可以正常访问，所以可以排除后端服务由于大量请求而打死的可能性，可以将重点放在MySQL上。
2. 查看MySQL的CPU使用率，发现在系统瘫痪的时候CPU使用率特别高，查看慢SQL日志，优化慢SQL
3. 优化后发现MySQL的CPU使用率以20min为周期很规律的波动，排查整个系统，看是否有20min的定时任务
4. 问题所在位于APP的首页，有一个10min刷新缓存的代码，但是由于业务不断发展，首页刷新到缓存竟然要15min，由于10min刷新不了，所以会有20min刷新首页的操作，这就是问题所在。

经验：

1. 避免写出慢SQL语句
2. 正确使用缓存
3. 上线一个定时监控和杀掉SQL的脚本，脚本每分钟执行一次，检查上一分钟超过阈值的SQL语句，将其杀死，可以避免由于部分SQL语句拖垮整个系统的问题，当然可能会导致部分功能失效了
4. 需要有降级方案，当首页访问超时的时候，由Nginx返回一个静态页面。



### 避免慢SQL

一台MySQL数据库，大致的数据处理极限是，处理1万条/s的简单SQL，当每秒只能处理几百的SQL时，数据库就已经是非常繁忙了

一般认为遍历行数在百万级别以内的，可以认为是安全的，而遍历行数在几百万的，就需要花费几秒了，而需要遍历千万级别的SQL语句则是很危险的，需要保证每个数据表数据量不要超过千万级别

经验：

1. 使用索引避免全表扫描
2. 使用explain分析SQL执行计划，优化SQL语句



### 应对高并发：使用缓存

使用Redis缓存MySQL是一个经典的做法

在缓存MySQL的数据表时，通常使用表的主键作为KEY保存在Redis中，还需要加上表的名字，比如订单表订单号为123，在Redis中的KEY可以是“order:123”，而Value保存序列化后的整条订单记录，可以选择JSON

#### 缓存策略

- Cache Aside：处理商品信息的读请求时，先去缓存查找，如果找到就直接返回缓存中的数据。如果在缓存中没找到，再去查数据库，把从数据库中查到的商品信息返回给页面，顺便把数据在缓存里也放一份。更新数据的时候，更新完数据库后，删除Redis中的缓存数据
- Read/Write Through：和上面的差别在于，更新数据的时候，更新完数据库后，会接着更新Redis的数据
- Write Behind

Read/Write Through会导致脏数据，而Cache Aside不会，尤其是在高并发下，推荐使用后者。

但是实际使用上是不能百分之百的避免缓存的脏数据，那我们可以使用一些方式来进行补偿

1. 把缓存的过期时间设置的相对短一些，一般在几十秒左右，这样即使产生了脏数据，几十秒之后就会自动恢复了。
2. 可以在请求中带上一个刷新标志位，如果用户在查看订单的时候，手动点击刷新，那就不走缓存直接去读数据库，也可以解决一部分问题。

#### 防止缓存穿透

- 当系统刚上线时，缓存为空，可以灰度发布，先接入少量请求，然后逐步增加系统请求量
- 缓存预热，提前将数据库中的数据写入到Redis中



### 应对高并发：使用读写分离

MySQL是典型的单机数据库，不支持分布式部署，用一个单机数据库的多个实例构建集群，提供分布式服务，是一件很困难的事情。因此，我们不对数据做分片，而是使用多个具有相同数据的数据库实例来分担大量的查询请求，这种方法称为读写分离。

读写分离实现起来简单，能够使系统性能提高几倍甚至几十倍

实施读写分离需要：

1. 构建一主多从的MySQL实例，并且让他们的数据保持同步；
2. 分离应用程序对数据库的读写请求，并且分别发送给从库和主库

分离应用程序需的读写请求有以下三种方法：

1. 纯手工方式。修改应用程序的DAO层代码，定义读写两个数据源，指定每个数据库请求的数据源；
2. 组件方式（推荐）。使用像Sharding-JDBC这样的第三方组件，组件集成在应用程序中，接管应用程序的所有数据库请求，分别路由到不同的数据库实例。对代码侵入性少，性能好且稳定。
3. 代理方式/中间件方式。在应用程序和数据库中间插入一个数据库代理实例，其伪装成一个单节点的MySQL实例，处理对数据库的所有请求，根据请求发送给不同的数据库实例。对应用程序是透明的，这种方式不需要修改应用程序代码逻辑，但是增加了调用的链路，有性能损失。常用的中间件有MyCat、Atlas、MySQL Router等

如果配置了多个从库，推荐使用“HAProxy+Keepalived”这对儿经典的组合来实现负载均衡和高可用，来给所有的从节点做一个高可用负载均衡方案，既可以避免某个从节点宕机导致业务可用率降低，也方便你后续随时扩容从库的实例数量。

读写分离带来的问题：主从延迟

1. 对于这种问题，我们需要重新设计业务逻辑，尽量规避更新数据后立即去从库查询刚刚更新的数据，而是延迟读取。比如支付成功后跳转到成功页面，还需要用户点击才能返回自己的账户。
2. 或者让更新和查询写成一个微服务，放到一个数据库事务中，保证了查询操作会在主库进行。
3. 强制将那些需要获取最新数据的请求路由到主库查询，虽然增加了主库的压力，但是能够保证获取到的数据是新的



### 主从数据库同步

当客户端提交一个事务到 MySQL 的集群，直到客户端收到集群返回成功响应，在这个过程中，MySQL 集群需要执行很多操作：主库需要提交事务、更新存储引擎中的数据、把 Binlog 写到磁盘上、给客户端返回响应、把 Binlog 复制到所有从库上、每个从库需要把复制过来的 Binlog 写到暂存日志中、回放这个 Binlog、更新存储引擎中的数据、给主库返回复制成功的响应。

默认情况下，MySQL 采用异步复制的方式，执行事务操作的线程不会等复制 Binlog 的线程。从库会有一个专门的线程读取Binlog。

同步复制则会在提交事务的时候，会等待所有数据复制到从库之后，在给客户端返回相应。自然这样性能和可用性是极差的

半同步复制，则是进行了折中，当事务线程不用等待所有的数据复制到从库，而是有部分复制成功（一般是一半）后就可以给客户端返回。

主库提交事务的线程等待复制的时间超时了，这种情况下事务仍然会被正常提交。并且，MySQL 会自动降级为异步复制模式，直到有足够多（rpl_semi_sync_master_wait_no_slave）的从库追上主库，才能恢复成半同步复制。如果这个期间主库宕机，仍然存在丢数据的风险



### 表内数据越来越多，查询越来越慢怎么办

可以有两个方法，第一，归档历史数据（优先使用）；第二：分库分表

#### 归档历史数据

把大量的历史数据移到历史表中，在线迁移，归档历史数据的流程（以下以订单表为例子）：

1. 创建一个跟订单表结构一模一样的历史订单表；
2. 把订单表中的历史数据查找出来，插入到历史订单表中。如果实现了读写分离，那么可以去从库中查找，插入到主库的历史订单表中
3. 测试和上线支持历史订单表的新代码，如果有问题，马上回滚
4. 等新代码没有问题之后，删除订单表中的历史数据
5. 最后，上线一个定期迁移历史数据的程序或脚本，定期从订单表中移动数据到历史订单表

如果可以接受停服，那么下面的做法是最快的

```mysql
-- 新建一个临时订单表
create table orders_temp like orders;

-- 把当前订单复制到临时订单表中
insert into orders_temp
  select * from orders
  where timestamp >= SUBDATE(CURDATE(),INTERVAL 3 month);

-- 修改替换表名
rename table orders to orders_to_be_droppd, orders_temp to orders;

-- 删除旧表
drop table orders_to_be_dropp
```

##### 如何删除数据

```mysql
# 通常的做法
delete from orders
where timestamp < SUBDATE(CURDATE(),INTERVAL 3 month)
order by id limit 1000;

# 如果订单号和时间成正相关，可以这样优化
select max(id) from orders
where timestamp < SUBDATE(CURDATE(),INTERVAL 3 month);

delete from orders
where id <= ?
order by id limit 1000;
```

语句中加了排序是因为删除的数据基本是相连的，在存储中是放置在一块的，能够提高效率，而且也有利于回收页

需要注意的是，删除后存储空间是不变的，因为删除操作只是标识了一下数据为“delete”，还是存在于磁盘中的，如果需要优化空间，可以使用`OPTIMIZE TABLE`重建表格，这个过程会锁表。这么优化有个前提条件，MySQL 的配置必须是每个表独立一个表空间（innodb_file_per_table = ON）

#### 分库分表

其实，对于数据我们能不拆能不分就不要拆分，拆分后开发和维护起来很麻烦，分库分表后对数据查询有很大的限制，但是面对海量数据，这是必须要做的。

遇到以下的场景就要考虑分库分表来解决问题：

1. 单表数据量超过千万行，单表查询缓慢（分表）
2. 数据库整体数据量很大，数据备份时间很长（分库）
3. 应用的并发量很大（分库）

分库分表可以解决数据查询慢的问题，可以提高并发量。一般情况下，我们的方案需要同时做分表和分库

对于Sharding Key的选择，也即是分片的依据，要看具体我们的业务是怎么访问数据的。

如果按照订单号来分，可以根据订单号查找到订单详情，但是查找用户下的所有订单就没法查了，因为此时查找条件是用户的id，可以解决的方法是按照用户id进行分片，订单号后面加上用户id的后几位，这样就支持按照订单号或者用户id查找了。

而对于其他需求，比如商户想看到自己所有的订单，或者和订单相关的报表，那么就无法完成了，解决方法是将数据同步到其他存储系统，在其他系统完成。

选择的解决方案：ShardingSphere 

##### 分库分表产生的问题

1. 分布式事务。如果事务操作的对象涉及到多个库，那么存在该问题，解决分布式事务有两种通用的方式：两阶事务提交（2PC）以及补偿事务提交（TCC），建议使用成熟的框架，比如SETA
2. 跨节点Join问题。我们尽量通过冗余表和冗余字段来避免跨节点Join
3. 跨节点分页查询。使用其他数据库同步Mysql数据，比如Elasticsearch来进行分页查询
4. 分布式全局主键。使用分布式id算法
5. 扩容。我们需要考虑可扩展的分库分表方式，避免扩容导致大量的数据迁移



##### 分片算法

哈希、查表法、分为分片（按照时间）

